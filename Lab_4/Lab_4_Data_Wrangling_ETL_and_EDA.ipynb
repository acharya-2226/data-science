{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b696cc6",
   "metadata": {},
   "source": [
    "\n",
    "# Lab 4: Data Wrangling, ETL, and Exploratory Data Analysis\n",
    "\n",
    "## Objectives\n",
    "- Understand the concepts of data wrangling, ETL processes, and exploratory data analysis (EDA).\n",
    "- Perform hands-on data wrangling and ETL processes on a dataset.\n",
    "- Conduct EDA to uncover insights using visualization and statistics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19721293-c2ca-4c7a-947d-d3068ec5c52a",
   "metadata": {},
   "source": [
    "## **Data Wrangling**\n",
    "- **Definition**: The process of cleaning, transforming, and preparing raw data into a format that is easy to analyze.\n",
    "- **Key Tasks**: \n",
    "  - Handling missing data\n",
    "  - Correcting inconsistencies\n",
    "  - Renaming columns\n",
    "  - Converting data types\n",
    "- **Purpose**: Ensures the dataset is structured and error-free for accurate analysis.\n",
    "\n",
    "---\n",
    "\n",
    "## **ETL (Extract, Transform, Load)**\n",
    "- **Definition**: A data integration process used to combine data from various sources and make it ready for analysis or storage in a database.\n",
    "  - **Extract**: Retrieve data from various sources like databases, APIs, or flat files.\n",
    "  - **Transform**: Modify the data into a suitable format, applying operations such as filtering, aggregating, or encoding.\n",
    "  - **Load**: Save the transformed data into a target system like a database, data warehouse, or file storage.\n",
    "\n",
    "---\n",
    "\n",
    "## **Dataset**\n",
    "- **Definition**: A collection of related data organized in a structured format, typically in rows and columns (like a spreadsheet or database table).\n",
    "- **Purpose**: Serves as the input for data wrangling, ETL processes, and analysis.\n",
    "\n",
    "---\n",
    "\n",
    "## **Exploratory Data Analysis (EDA)**\n",
    "- **Definition**: The process of analyzing and visualizing data to uncover patterns, relationships, and insights.\n",
    "- **Key Steps**:\n",
    "  - **Descriptive Statistics**: Understanding measures like mean, median, and standard deviation.\n",
    "  - **Visualization**: Using charts, graphs, or plots to interpret data trends and distributions.\n",
    "  - **Hypothesis Generation**: Formulating questions or assumptions about the data based on observations.\n",
    "- **Purpose**: Helps in understanding data properties and preparing it for advanced analysis or modeling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52eb838-553b-4711-817f-4e83af910ea9",
   "metadata": {},
   "source": [
    "# **Online Resources to Get Datasets**\n",
    "\n",
    "## 1. **[Kaggle](https://www.kaggle.com/)**\n",
    "- **Description**: A platform for data science and machine learning enthusiasts.\n",
    "- **Features**:\n",
    "  - Extensive collection of datasets across various domains.\n",
    "  - Community discussions and shared notebooks for insights.\n",
    "  - Free download with a Kaggle account.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. **[UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php)**\n",
    "- **Description**: A repository of machine learning datasets maintained by the University of California, Irvine.\n",
    "- **Features**:\n",
    "  - Datasets tailored for machine learning tasks.\n",
    "  - Covers diverse topics such as healthcare, engineering, and biology.\n",
    "  - Available in plain text or CSV format.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. **[Google Dataset Search](https://datasetsearch.research.google.com/)**\n",
    "- **Description**: A search engine designed to find datasets from various sources.\n",
    "- **Features**:\n",
    "  - Indexed datasets from government, research, and private organizations.\n",
    "  - Includes links to datasets hosted on external platforms.\n",
    "  - Free to use.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. **[Data.gov](https://www.data.gov/)**\n",
    "- **Description**: A U.S. government portal providing open datasets.\n",
    "- **Features**:\n",
    "  - Topics include agriculture, climate, education, and public safety.\n",
    "  - Useful for academic, commercial, and personal projects.\n",
    "  - Data formats include CSV, JSON, and APIs.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. **[FiveThirtyEight](https://data.fivethirtyeight.com/)**\n",
    "- **Description**: Datasets from FiveThirtyEightâ€™s data-driven journalism.\n",
    "- **Features**:\n",
    "  - Covers sports, politics, economics, and culture.\n",
    "  - Free to use and well-documented.\n",
    "  - Comes with insights and context for better understanding.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. **[Awesome Public Datasets](https://github.com/awesomedata/awesome-public-datasets)**\n",
    "- **Description**: A curated list of free public datasets available on GitHub.\n",
    "- **Features**:\n",
    "  - Datasets span a wide range of categories, including health, finance, and technology.\n",
    "  - Continuously updated with contributions from the community.\n",
    "  - Provides links and descriptions for easy access.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a66d890",
   "metadata": {},
   "source": [
    "\n",
    "## Step 1: Dataset Introduction\n",
    "\n",
    "In this lab, we will use a sample dataset. Download or load the dataset into your working directory.\n",
    "\n",
    "For example, we will use the **Titanic dataset** available in CSV format.\n",
    "\n",
    "### Instructions:\n",
    "1. Import necessary libraries.\n",
    "2. Load the dataset using Pandas.\n",
    "3. Explore the dataset structure.\n",
    "\n",
    "#### Example Code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b66646e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "file_path = 'titanic.csv'  # Update this path as necessary\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display first few rows\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ad3744",
   "metadata": {},
   "source": [
    "\n",
    "## Step 2: Data Wrangling\n",
    "\n",
    "### Tasks:\n",
    "1. Handle missing values (e.g., filling, dropping).\n",
    "2. Remove duplicates.\n",
    "3. Rename columns for clarity.\n",
    "4. Convert data types if necessary.\n",
    "\n",
    "#### Example Code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1baa10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values\n",
    "# Fill missing 'Age' values with the median of the 'Age' column.\n",
    "# This helps to avoid dropping rows and ensures no data is lost.\n",
    "df['Age'] = df['Age'].fillna(df['Age'].median())  # Fill missing Age values with the median\n",
    "\n",
    "# Drop rows where 'Embarked' column has missing values.\n",
    "# This assumes that 'Embarked' is critical for analysis, and rows with missing 'Embarked' should be discarded.\n",
    "df.dropna(subset=['Embarked'], inplace=True)  # Drop rows where 'Embarked' is missing\n",
    "\n",
    "# Meaning of the Embarked column:\n",
    "# C: Passenger boarded in Cherbourg.\n",
    "# Q: Passenger boarded in Queenstown.\n",
    "# S: Passenger boarded in Southampton.\n",
    "\n",
    "# Remove duplicate rows in the dataframe.\n",
    "# This ensures that the data is unique and avoids bias in analysis caused by repeated records.\n",
    "df = df.drop_duplicates()  # Remove duplicates and reassign the dataframe\n",
    "\n",
    "# Rename columns for clarity to make the dataset more understandable.\n",
    "# The 'Pclass' column is renamed to 'Passenger_Class' and 'Fare' to 'Ticket_Fare' to make the names more descriptive.\n",
    "df.rename(columns={'Pclass': 'Passenger_Class', 'Fare': 'Ticket_Fare'}, inplace=True)  # Renaming columns\n",
    "\n",
    "# Convert the 'Passenger_Class' column to the 'category' data type.\n",
    "# This is an optimization technique because 'Passenger_Class' has a limited number of categories and doesn't need to be stored as a regular integer or string.\n",
    "df['Passenger_Class'] = df['Passenger_Class'].astype('category')  # Convert to category\n",
    "\n",
    "# Display the updated dataframe structure with data types after the changes.\n",
    "# This will show the updated column data types and confirm the changes made in the previous steps.\n",
    "df.info()  # Check updated data types\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1670a7f7",
   "metadata": {},
   "source": [
    "\n",
    "## Step 3: ETL Process\n",
    "\n",
    "### Tasks:\n",
    "1. Extract: Load data from a source (done earlier).\n",
    "2. Transform: Clean, aggregate, and modify data.\n",
    "3. Load: Save processed data into a new file format.\n",
    "\n",
    "#### Example Code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585ea70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Transform: Add a new column\n",
    "df['Family_Size'] = df['SibSp'] + df['Parch']\n",
    "\n",
    "# Save the transformed data\n",
    "output_path = 'processed_titanic.csv'\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"Processed data saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5c3e94",
   "metadata": {},
   "source": [
    "\n",
    "## Step 4: Exploratory Data Analysis (EDA)\n",
    "\n",
    "### Tasks:\n",
    "1. Calculate descriptive statistics.\n",
    "2. Visualize data trends and distributions.\n",
    "\n",
    "#### Example Code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d59d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt  # For creating plots and visualizations\n",
    "import seaborn as sns  # For advanced visualizations with better styling\n",
    "\n",
    "# Descriptive statistics\n",
    "# This gives an overview of the numerical columns in the dataset, including count, mean, standard deviation, etc.\n",
    "print(df.describe())\n",
    "\n",
    "# Visualization: Age distribution\n",
    "# Create a figure with specified size\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Create a histogram to visualize the distribution of the 'Age' column\n",
    "# kde=True adds a Kernel Density Estimate (smooth curve) to the histogram\n",
    "sns.histplot(df['Age'], kde=True, bins=30)\n",
    "\n",
    "# Adding title and labels to the plot for clarity\n",
    "plt.title('Age Distribution')  # Title of the plot\n",
    "plt.xlabel('Age')  # X-axis label\n",
    "plt.ylabel('Frequency')  # Y-axis label\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "# Visualization: Survival rate by passenger class\n",
    "# Create a figure with specified size\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Create a bar plot to show the survival rate for each passenger class\n",
    "# The 'Passenger_Class' is on the x-axis, and 'Survived' is the y-axis representing the survival rate\n",
    "sns.barplot(x='Passenger_Class', y='Survived', data=df)\n",
    "\n",
    "# Adding title and labels to the plot for clarity\n",
    "plt.title('Survival Rate by Passenger Class')  # Title of the plot\n",
    "plt.xlabel('Passenger Class')  # X-axis label\n",
    "plt.ylabel('Survival Rate')  # Y-axis label\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543ed9ca-1dc2-440a-9132-be02f58c063b",
   "metadata": {},
   "source": [
    "## Practice Questions for Titanic Dataset\n",
    "\n",
    "### 1. **Data Preprocessing:**\n",
    "   - **Question:** Write a Python function to calculate the percentage of missing values for each column in the dataset. Use the function to identify columns with missing values in the Titanic dataset and display their percentages. Visualize the missing data percentages using a **bar plot**.\n",
    "   - **Hint:** Use the `isnull()` method combined with `sum()` to count missing values for each column. Divide the missing values by the total number of rows to calculate percentages. For visualization, use Matplotlib or Seaborn to create a bar plot.\n",
    "\n",
    "### 2. **Feature Creation:**\n",
    "   - **Question:** Create a new column **Age_Category** by categorizing passengers into three groups: **Child** (0-12), **Teen** (13-19), **Adult** (20+). Calculate the survival rate for each group and compare the results.\n",
    "   - **Hint:** Use the `pd.cut()` method to create bins for age categories. Group the data by the new column using `groupby()` and calculate the mean survival rate for each group.\n",
    "\n",
    "### 3. **Family Impact on Survival:**\n",
    "   - **Question:** Investigate the impact of family size on survival. Create a new column **Large_Family** (True if **Family_Size** > 3, False otherwise). Calculate and visualize the survival rate for passengers with large families versus those without using a **bar plot**.\n",
    "   - **Hint:** Family size can be calculated as the sum of `SibSp` and `Parch` plus one (self). Use a conditional statement (`> 3`) to create the new column. Use `groupby()` to find the survival rates and visualize the results with a bar plot.\n",
    "\n",
    "### 4. **Passenger Class and Fare Analysis:**\n",
    "   - **Question:** Compare the distribution of **Fare** across the different **Passenger_Class** categories using a **box plot**. What can you conclude about the distribution of ticket prices for each class? Are there any outliers?\n",
    "   - **Hint:** Use Seaborn's `boxplot()` function with `Pclass` on the x-axis and `Fare` on the y-axis. Look for the spread of values and points outside the whiskers to identify outliers.\n",
    "\n",
    "### 5. **Embarked Location Analysis:**\n",
    "   - **Question:** Analyze the survival rates based on the **Embarked** column (Cherbourg, Queenstown, and Southampton). Create a **bar plot** to visualize the survival rate for passengers who boarded at each of the three locations. Which embarkation point had the highest survival rate?\n",
    "   - **Hint:** Use `groupby()` on the Embarked column and calculate the mean survival rate. Use Matplotlib or Seaborn to create a bar plot showing survival rates.\n",
    "\n",
    "### 6. **Passenger Cabin Analysis:**\n",
    "   - **Question:** Investigate the **Cabin** column to check for missing or irregular data. Create a new column **Has_Cabin** where 1 indicates that a passenger has a cabin, and 0 indicates they do not. Calculate the survival rate for passengers with and without cabins. Visualize the results using a **bar plot**.\n",
    "   - **Hint:** Use the `notnull()` method on the Cabin column to check if a passenger has a cabin. Convert the Boolean values to integers for the new column. Use `groupby()` to calculate survival rates and a bar plot for visualization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b83bc7e-99b8-4a0d-b42b-9ac5c3b12b5d",
   "metadata": {},
   "source": [
    "## Additional Practice Question: Wine Quality Dataset - Basic Data Exploration\n",
    "\n",
    "**Question:**\n",
    "- Load the **Wine Quality Dataset** from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/wine+quality) or from a CSV file.\n",
    "- Perform the following tasks:\n",
    "  1. Display the first 5 rows of the dataset.\n",
    "  2. Check if there are any missing values in the dataset.\n",
    "  3. Calculate and print the median of the **alcohol** and **pH** columns.\n",
    "  4. Create a **box plot** to show the distribution of the **fixed acidity**.\n",
    "  5. Create a **pair plot** to visualize the relationships between **citric acid**, **residual sugar**, and **density**.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
